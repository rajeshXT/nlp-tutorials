{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVrcHNZpQLUz"
   },
   "source": [
    "### **TF-IDF: Exercises**\n",
    " \n",
    "- Humans ðŸ‘¦ show different emotions/feelings based on the situations and communicate them through facial expressions or in form of words.\n",
    " \n",
    "- In Social Media like Twitter and Instagram, many people express their views through comments about a particular event/scenario and these comments may address the feelings like sadness, happiness, joy, sarcasm, fear, and many other.\n",
    " \n",
    "- For a given comment/text, we are going to use classical NLP techniques and classify under which emotion that particular comment belongs!\n",
    " \n",
    "- We are going to use techniques like Bag of grams, n-grams, TF-IDF, etc. for text representation and apply different classification algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wU5KDovsV9ez"
   },
   "source": [
    "### **About Data: Emotion Detection**\n",
    "\n",
    "Credits: https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp\n",
    "\n",
    "\n",
    "- This data consists of two columns.\n",
    "        - Comment\n",
    "        - Emotion\n",
    "- Comment are the statements or messages regarding to a particular event/situation.\n",
    "\n",
    "- Emotion feature tells whether the given comment is fear ðŸ˜¨, Anger ðŸ˜¡, Joy ðŸ˜‚.\n",
    "\n",
    "- As there are only 3 classes, this problem comes under the **Multi-Class Classification.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "8ML2s0KWVXmv",
    "outputId": "4284d452-b3f4-4998-a2bf-9fd7aa273207"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i seriously hate one subject to death but now ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im so full of life i feel appalled</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sit here to write i start to dig out my feel...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive been really angry with r and i feel like a...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel suspicious if there is no one outside l...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Emotion\n",
       "0  i seriously hate one subject to death but now ...    fear\n",
       "1                 im so full of life i feel appalled   anger\n",
       "2  i sit here to write i start to dig out my feel...    fear\n",
       "3  ive been really angry with r and i feel like a...     joy\n",
       "4  i feel suspicious if there is no one outside l...    fear"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "#read the dataset with name \"Emotion_classify_Data.csv\" and store it in a variable df\n",
    "df=pd.read_csv(\"Emotion_classify_Data.csv\")\n",
    "\n",
    "#print the shape of dataframe\n",
    "df.shape\n",
    "\n",
    "#print top 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "joLuZmFpT-fY",
    "outputId": "77d48614-f6b3-4227-e90e-dc8ddb17381b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anger    2000\n",
       "joy      2000\n",
       "fear     1937\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the distribution of Emotion\n",
    "df['Emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "qPxiqT_TT-hx",
    "outputId": "d58985b6-c81c-48b5-de9b-74735bb6b133"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Emoton_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i seriously hate one subject to death but now ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im so full of life i feel appalled</td>\n",
       "      <td>anger</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sit here to write i start to dig out my feel...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive been really angry with r and i feel like a...</td>\n",
       "      <td>joy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel suspicious if there is no one outside l...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Emotion  Emoton_num\n",
       "0  i seriously hate one subject to death but now ...    fear           0\n",
       "1                 im so full of life i feel appalled   anger           1\n",
       "2  i sit here to write i start to dig out my feel...    fear           0\n",
       "3  ive been really angry with r and i feel like a...     joy           2\n",
       "4  i feel suspicious if there is no one outside l...    fear           0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add the new column \"Emotion_num\" which gives a unique number to each of these Emotions\n",
    "#joy --> 0, fear --> 1, anger --> 2\n",
    "\n",
    "df['Emoton_num']=df['Emotion'].map({'anger':1,'joy':2,\"fear\":0})\n",
    "#checking the results by printing top 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PE-c0zbDXTEm"
   },
   "source": [
    "### **Modelling without Pre-processing Text data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NjJqi7UBT-nr"
   },
   "outputs": [],
   "source": [
    "#import train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Do the 'train-test' splitting with test size of 20%\n",
    "X=df['Comment']\n",
    "y=df['Emoton_num']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=2022,stratify=y,test_size=0.2)\n",
    "\n",
    "#Note: Give Random state 2022 and also do the stratify sampling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5lAD0iqGcdCn",
    "outputId": "4efb3c3c-0ad4-4501-d815-35a902095848"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4749,)\n",
      "(1188,)\n"
     ]
    }
   ],
   "source": [
    "#print the shapes of X_train and X_test\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6h8ZZLxZd79"
   },
   "source": [
    "\n",
    "**Attempt 1** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using CountVectorizer with only trigrams.\n",
    "- use **RandomForest** as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vGg2iXv6g40l",
    "outputId": "3f895ca5-7606-4220-b9a2-7c26d9160a9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.77      0.52       388\n",
      "           1       0.52      0.33      0.40       400\n",
      "           2       0.56      0.24      0.34       400\n",
      "\n",
      "    accuracy                           0.45      1188\n",
      "   macro avg       0.49      0.45      0.42      1188\n",
      "weighted avg       0.49      0.45      0.42      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import CountVectorizer, RandomForest, pipeline, classification_report from sklearn \n",
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report,roc_auc_score,auc,accuracy_score,roc_curve,accuracy_score\n",
    "\n",
    "#1. create a pipeline object\n",
    "model_pipe=Pipeline([\n",
    "    (\"count\",CountVectorizer(ngram_range=(3,3))),\n",
    "    ('Random',RandomForestClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "model_pipe.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred=model_pipe.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "clf=classification_report(y_test,y_pred)\n",
    "print(\"Classification Report \\n\\n\",clf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I08-kc_JYCNL"
   },
   "source": [
    "\n",
    "**Attempt 2** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using CountVectorizer with both unigram and bigrams.\n",
    "- use **Multinomial Naive Bayes** as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8zetSmBrXmjM",
    "outputId": "b372f53c-8cbc-496f-ef4d-9fecff044230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report :\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       388\n",
      "           1       0.88      0.89      0.88       400\n",
      "           2       0.89      0.87      0.88       400\n",
      "\n",
      "    accuracy                           0.88      1188\n",
      "   macro avg       0.88      0.88      0.88      1188\n",
      "weighted avg       0.88      0.88      0.88      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import MultinomialNB from sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#1. create a pipeline object\n",
    "model_pipe = Pipeline([\n",
    "    ('count',CountVectorizer(ngram_range=(1,2))),\n",
    "    ('naive',MultinomialNB())\n",
    "    ])\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "model_pipe.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred=model_pipe.predict(X_test)\n",
    "\n",
    "#4. print the classfication report\n",
    "clf=classification_report(y_test,y_pred)\n",
    "print('Classification Report :\\n\\n',clf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Wde4r_-YwU-"
   },
   "source": [
    "\n",
    "**Attempt 3** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using CountVectorizer with both unigram and Bigrams.\n",
    "- use **RandomForest** as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n0dG2tc0X7SK",
    "outputId": "f6eddad9-a55b-4fde-eea2-2cbc002f6d4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiction Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92       388\n",
      "           1       0.94      0.87      0.90       400\n",
      "           2       0.86      0.95      0.90       400\n",
      "\n",
      "    accuracy                           0.91      1188\n",
      "   macro avg       0.91      0.91      0.91      1188\n",
      "weighted avg       0.91      0.91      0.91      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. create a pipeline object\n",
    "Pipe=Pipeline([\n",
    "    ('count',CountVectorizer(ngram_range=(1,2))),\n",
    "    ('Random',RandomForestClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "Pipe.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred=Pipe.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "clf=classification_report(y_test,y_pred)\n",
    "print('Classifiction Report \\n\\n',clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmrXmL_3Z2y6"
   },
   "source": [
    "\n",
    "**Attempt 4** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using **TF-IDF vectorizer** for Pre-processing the text.\n",
    "- use **RandomForest** as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "djsDsThaaCSO",
    "outputId": "b4514ab2-f6ad-45e1-b91b-e88393e975e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       388\n",
      "           1       0.92      0.86      0.89       400\n",
      "           2       0.88      0.94      0.91       400\n",
      "\n",
      "    accuracy                           0.90      1188\n",
      "   macro avg       0.90      0.90      0.90      1188\n",
      "weighted avg       0.90      0.90      0.90      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import TfidfVectorizer from sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#1. create a pipeline object\n",
    "model_pipe=Pipeline([\n",
    "    ('tf_idf',TfidfVectorizer()),\n",
    "    ('Random_forest',RandomForestClassifier())\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "model_pipe.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred=model_pipe.predict(X_test)\n",
    "\n",
    "#4. print the classfication report\n",
    "clf=classification_report(y_test,y_pred)\n",
    "print('Classification Report \\n',clf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ACq6pDkZ4sA"
   },
   "source": [
    "<h3>Use text pre-processing to remove stop words, punctuations and apply lemmatization </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "tj_xYgthX7UF"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# load english language model and create nlp object from it\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "\n",
    "#use this utility function to get the preprocessed text data\n",
    "def preprocess(text):\n",
    "    # remove stop words and lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    \n",
    "    return \" \".join(filtered_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xqW1i19wX7Xq"
   },
   "outputs": [],
   "source": [
    "# create a new column \"preprocessed_comment\" and use the utility function above to get the clean data\n",
    "# this will take some time, please be patient\n",
    "df['preprocessed_comment'] = df['Comment'].apply(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Comment', 'Emotion', 'Emoton_num', 'preprocessed_comment'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q24oRlMcai9l"
   },
   "source": [
    "**Build a model with pre processed text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ahdd2mgxX7dM"
   },
   "outputs": [],
   "source": [
    "#Do the 'train-test' splitting with test size of 20% with random state of 2022 and stratify sampling too\n",
    "#Note: Use the preprocessed_Comment\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=df['preprocessed_comment']\n",
    "y =df['Emoton_num']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,stratify=y,random_state=2022,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqonfpeYasOE"
   },
   "source": [
    "**Let's check the scores with our best model till now**\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1wYgFs3auLQ"
   },
   "source": [
    "**Attempt1** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using CountVectorizer with both unigrams and bigrams.\n",
    "- use **RandomForest** as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Khtu32z1XmmE",
    "outputId": "b5f67051-d0e3-4e2e-e342-8297938090ce"
   },
   "outputs": [],
   "source": [
    "#1. create a pipeline object\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "\n",
    "model_pipeline=make_pipeline(CountVectorizer(ngram_range=(1,2)),RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Khtu32z1XmmE",
    "outputId": "b5f67051-d0e3-4e2e-e342-8297938090ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classfication Report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.94       388\n",
      "           1       0.92      0.94      0.93       400\n",
      "           2       0.91      0.94      0.92       400\n",
      "\n",
      "    accuracy                           0.93      1188\n",
      "   macro avg       0.93      0.93      0.93      1188\n",
      "weighted avg       0.93      0.93      0.93      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2. fit with X_train and y_train\n",
    "\n",
    "model_pipeline.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "#4. print the classfication report\n",
    "clf_report =classification_report(y_test,y_pred)\n",
    "print('Classfication Report \\n\\n',clf_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9GZPaQbbJbx"
   },
   "source": [
    "\n",
    "**Attempt 2** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the data.\n",
    "\n",
    "**Note:**\n",
    "- using **TF-IDF vectorizer** for pre-processing the text.\n",
    "- use **RandomForest** as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2y1Cy4Bauxu",
    "outputId": "ac6bf255-a218-400c-c4a9-790f4a89dfb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiction Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       388\n",
      "           1       0.93      0.89      0.91       400\n",
      "           2       0.91      0.95      0.93       400\n",
      "\n",
      "    accuracy                           0.92      1188\n",
      "   macro avg       0.92      0.92      0.92      1188\n",
      "weighted avg       0.92      0.92      0.92      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. create a pipeline object\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model_pipe=make_pipeline(TfidfVectorizer(),RandomForestClassifier())\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "model_pipe.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred=model_pipe.predict(X_test)\n",
    "y_pred_proba=model_pipeline.predict_proba(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "clf_rp =classification_report(y_test,y_pred)\n",
    "print('Classifiction Report \\n',clf_rp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Please write down Final Observations**\n",
    " As part of this exercise we have trained the data with algorithms like **Multinomial Naive Bayes** and **Random Forest** which are most used and provide good results for text related problems.\n",
    "\n",
    "- As Machine learning algorithms do not work on text data directly, we need to convert them into numeric vectors and feed that into models while training. For this purpose, we have used Bag of words(unigrams, bigrams, n-grams) and TF-IDF text representation techniques.\n",
    "\n",
    "\n",
    "**Key Findings**\n",
    "\n",
    "- As the n_gram range keeps increasing, there's drastic fall of improvement in performance metrics.\n",
    "\n",
    "- There's seen a significant improvement in results before pre-processing and after pre-processing the data.\n",
    "\n",
    "- TF-IDF and Bag of words both performed equally well in performance metrics like Recall and F1-score.\n",
    "\n",
    "- Random Forest performed quite well when compared to Multinomial Naive Bayes.\n",
    "\n",
    "**Machine Learning is like a trial and error scientific method, where we keep trying all the possible algorithms we have and select the one which gives good results and satisfies the requirements like latency, interpretability, etc.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ta2cWBUkfKel"
   },
   "source": [
    "## [**Solution**](./tf_idf_exercise_solutions.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = np.array(y_test)\n",
    "y_scores = np.array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fps,tps,threshold\u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43movr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_ranking.py:565\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m multi_class \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    564\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_class must be in (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movo\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 565\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_multiclass_roc_auc_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    569\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_ranking.py:631\u001b[0m, in \u001b[0;36m_multiclass_roc_auc_score\u001b[1;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;124;03m\"\"\"Multiclass roc auc score.\u001b[39;00m\n\u001b[0;32m    592\u001b[0m \n\u001b[0;32m    593\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    628\u001b[0m \n\u001b[0;32m    629\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;66;03m# validation of the input y_score\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(\u001b[38;5;241m1\u001b[39m, \u001b[43my_score\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m):\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget scores need to be probabilities for multiclass \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroc_auc, i.e. they should sum up to 1.0 over classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    635\u001b[0m     )\n\u001b[0;32m    637\u001b[0m \u001b[38;5;66;03m# validation for multiclass parameter specifications\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:48\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     47\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "fps,tps,threshold= roc_auc_score(y_t,y_scores, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tf_idf_exercise.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
